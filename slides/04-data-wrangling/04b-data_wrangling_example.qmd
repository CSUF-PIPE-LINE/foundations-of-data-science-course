---
title: "Example: A Data Wrangling Pipeline"
format: revealjs
editor: visual
execute:
  echo: TRUE
---

## How We Made the `loans` Dataset

-   This is a real example of a real data wrangling pipeline that we used to create the `loans_OC.csv` file you have been working with

-   This is *much* more streamlined than how it actually happened

    -   Do not expect your data massaging to work perfectly the first time!
    
    -   Thinking through the process can be as important as writing the code!

## Original Data

-   The original data file from the Consumer Financial Protection Bureau contained information about all 3.36 million loan applications from California in 2021

    -   1.3 GB csv file!

    -   Over 88,000 parsing issues when first importing into R

## Step 1: Look at the Data Dictionary

-   There were 99 variables in the original dataset

-   Many were redundant or irrelevant to our goals

-   Some had weird names or values

-   Reading and understanding the data dictionary helped us understand what those variables actually represent

## Step 2: Recode Variables with `mutate`

-   Many categorical variables had numerical or otherwise difficult-to-work-with values

-   The data dictionary (usually) told us which values corresponded to which groups

-   We used `mutate` to change category names so they were shorter or more informative

    -   Sometimes we combined multiple values into the same group

    -   Lots of `if_else` and `case_when`!

## Recoding Is Not Always Simple!

-   The most annoying variable was `lei`

    -   A unique 20-character code for a financial institution

    -   We manually searched a database to see which `lei` code corresponded to which institution

    -   If the institution processed fewer than 1000 loan applications from the Southern California area, we marked it as "Other" 
    
    -   This ended up as a 65-line `case_when` statement

## Step 3a: `filter` for Orange County

-   There was a variable named `county_code` in our dataset, and we eventually figured out that the value "06059" the tract was in Orange County

    -   We needed help from the Census Bureau website:

        -   The state code for CA is 06

        -   The county code for Orange County, CA is 059

-   Filtering reduced from 3.36 million rows to about 275,000

## Step 3b: `filter` for Only the Applications of Interest

-   We kept only applications for conventional first mortgages on a home purchase

-   We removed reverse mortgages and other weird types of loans

-   We removed applications where the applicants' race, ethnicity, or sex was unclear

-   Filtering reduced from about 275,000 rows to 24,472

## When Did We Explore the Data?

-   As we were doing all of this data processing, we were *regularly* making tables and graphs of the data

    -   Figuring out what values were present and how often they occurred

    -   Making sure the newly created datasets looked like we expected

    -   Also referring back to the data dictionary to figure out what those values meant!
    

## Step 4: `select` and Rename Relevant Columns

-   17 columns were potentially relevant to our goals

-   Selecting columns reduced from 99 columns to 17

    -   `city` is not one of them!

-   We also renamed some columns within `select`:

    -   `new_variable_name = old_variable_name`

    -   For example: `select(instituion = lei)`

## Step 5: Match Census Tracts to Cities

-   We found a map indicating the boundaries of both the census tracts and the cities

-   There are 567 different census tracts in Orange County

-   We created a new dataset with 567 rows and 2 columns

    -   Census tract number and city covering most of the tract

    -   Some census tracts in the dataset did not exist on the map!

    -   Some census tracts on the map did not exist in the dataset!

## Step 6: Merge the Two Datasets

```{r}
#| label: load packages 
library(tidyverse) 
library(janitor) # redo the merging example
```

```{r}
#| label: import data with here

loans <- readr::read_csv(here::here("Data", "loans_cleaned.csv"))
tracts <- readr::read_csv(here::here("Data", "OC_tracts.csv"))
```
-   In SQL database terminology, we want to `join` these two datasets together

-   There are 3 main types of joins

    -   The main distinction is in which unmatched rows are kept

## Inner Join

```{r}
#| label: Inner join loans and tracts

ij_loans <- loans |> # source dataset
  inner_join(
    tracts, # dataset to merge with it
    by = "census_tract" # common variable in the two datasets
  )

```

-   An inner join keeps *only* the rows in the first dataset that match something in the second dataset

```{r}
#| label: number of rows in each dataset - inner join
c(loans = nrow(loans),
  tracts = nrow(tracts),
  joined = nrow(ij_loans))
```

## What Gets Kept in an Inner Join?

-   Only the 20518 rows in the `loans` dataset that correspond to a census tract on the map are included in the inner join

```{r}
#| label: check bottom of inner join
ij_loans |>
  select(census_tract, loan_amount, city) |>
  tail(5)
```

## Full Join

```{r}
#| label: Full join loans and tracts

fj_loans <- loans |> # source dataset
  full_join(
    tracts, # dataset to merge with it
    by = "census_tract" # common variable in the two datasets
  )

```

-   A full join (or full outer join) keeps *all* rows in each dataset, whether or not they match anything in the other dataset

```{r}
#| label: number of rows in each dataset - full join
c(loans = nrow(loans),
  tracts = nrow(tracts),
  joined = nrow(fj_loans))
```

## What Gets Kept in a Full Join?

-   All 24472 rows in the `loans` dataset are included

-   Additionally, 12 census tracts not found in the `loans` dataset are included

    -   Potential mismatch between tract number in the `loans` dataset and tract number on the map?

    -   R adds 12 rows to the bottom of the dataset containing values for *just* the census tract and city

        -   All other variables are coded as missing (`NA`)

## Left Join

```{r}
#| label: left join loans and tracts

lj_loans <- loans |> # source dataset
  left_join(
  tracts, # dataset to merge with it
  by = "census_tract" # common variable in the two datasets
  )

```

-   A left join (or left outer join) keeps the rows in the *source* dataset, whether or not they match anything in the other dataset

```{r}
#| label: number of rows in each dataset - left join
c(loans = nrow(loans),
  tracts = nrow(tracts),
  joined = nrow(lj_loans))
```

## What Gets Kept in a Left Join?

-   All 24472 rows in the `loans` dataset are included

-   The 12 census tracts not found in the `loans` dataset are *not* added

```{r}
#| label: check bottom of left join
lj_loans |>
  select(census_tract, loan_amount, city) |>
  tail(5)
```

## Choosing a Join

- `inner_join` is almost never recommended because too many observations are dropped

- `full_join` is used when you want *everything* regardless of which dataset it comes from

- We chose to use `left_join` because we we wanted to add additional information (if present) to each application in the `loans` dataset

    -   Think about why you are merging and what you want your merged dataset to look like before doing it!

## Different Datasets, Different Information, Same Variable Name

-   Sometimes the same variable name is present in both datasets but the variable represents *different* information in each dataset

    -   So we don't want to match based on these variables!

-   We saw this in the Summarizing Categorical Data Activity when we tried to create one table with the percentages and the group totals

## Code We Wrote to Create the Tables

```{r}
#| label: example from janitor

ethnicity_totals <- loans |>
  tabyl(ethnicity, action) |>
  adorn_totals(c("col"))

ethnicity_pcts <- loans |>
  tabyl(ethnicity, action) |>
  adorn_percentages(denominator = "row") |>
  adorn_pct_formatting(digits = 1)

names(ethnicity_totals)
names(ethnicity_pcts)
```

## Noting Which `Approved` Variable Came from Which Dataset

```{r}
#| label: using left join with the tables
#| code-line-numbers: "5"
ethnicity_pcts |>
  left_join(
    ethnicity_totals,
    by = "ethnicity",
    suffix = c("_pct", "_total")
  )
```

## More Complicated Matching

-   We may need to match based on *multiple* variables

-   The variables we want to match on may have different names in the two datasets

-   We may want to match based on more complicated overlaps 

-   Two or more of these situations may occur!

## Use `join_by` for More Complicated Matching

-   Just like with `filter`, we create a list of one or more expressions that evaluate to `TRUE` or `FALSE`

-   The left side of the expression refers to the source dataset and the right side to the dataset we are merging with it

```{r}
#| label: example join_by

tracts2 <- tracts |>
  rename(tract = census_tract) # rename census_tract to tract

# Create join_by first
by <- join_by(census_tract == tract)

jb_loans <- loans |>
  left_join(tracts2, by = by)
```
