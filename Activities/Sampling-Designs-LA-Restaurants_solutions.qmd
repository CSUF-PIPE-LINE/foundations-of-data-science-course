---
title: "Sampling Designs: Restaurant Inspections in Los Angeles County"
format: html
editor: visual
---

In this activity, we're going to obtain samples of different kinds from the `inspections` dataset. The techniques we learn for randomly sampling from a population are also useful for randomly dividing our collected data into a *training* set and *holdout* set for modeling.

In the `inspections` dataset, we assume that our population is restaurant inspections during the time frame covered by the dataset, and that all inspections in the population are included in the dataset. For many "big" datasets, this is a dangerous assumption!

```{r}
#| label: import packages
here::i_am("Activities/Sampling-Designs-LA-Restaurants.qmd")

library(tidyverse)
library(rsample)
library(lubridate)
```

```{r}
#| label: import data
inspections <- readr::read_csv(here::here("Data/inspections.csv"))
```

## Sampling vs. Splitting

When we *sample* from the population, we do so *before* collecting data. Since collecting data can be expensive, we decide which observations from the population we want to collect that data about before collecting it. Typically, samples are *small* (< 5%) subsets of the population.

When we *split* a dataset into training and "test" sets, we do so *after* collecting data. All data in the original dataset is put in one of the two datasets, and the "test" set is immediately removed (and we don't do anything with it until we've selected our final model). Typically, the training set is the *majority* (50%-90%) of the original dataset.

## Convenience Sampling

In convenience sampling, our primary concern is getting data in the first place. We will get data from whatever sample is "easy" to get data from.

In a "training/test" split, convenience sampling usually refers to non-randomly splitting the dataset. For example,

```{r}
#| label: filter to one zip code

train_set <- inspections |>
  filter(FACILITY_CITY == "LOS ANGELES")
test_set <- inspections |>
  filter(FACILITY_CITY != "LOS ANGELES")
```

means that we will train our model on *only* inspections in the city of Los Angeles.

### Your Turn

1. Why would training our model on *only* inspections in the city of Los Angeles be a problem?

## Random Sampling

To use the rsample package to do random sampling, the code looks like:

```{r}
#| label: general random sampling algorithm
#| eval: false

set.seed(some seed)
train_set <- sampling_frame |>
  initial_split(
    prop = proportion_of_pop_in_sample
    # potentially other arguments go here
    ) |>
  training() # extract the selected rows of the dataset
```

## Simple Random Sampling

In simple random sampling, we obtain a list of every observation in the population that we could possibly get data from, and then randomly "pick observations out of a hat".

Therefore, we don't need extra arguments to `initial_split`.

```{r}
#| label: simple random sampling

set.seed(1355)
inspections_srs <- inspections |>
  initial_split(
    prop = 0.05
    ) |>
  training() # extract the selected rows of the dataset

```

### Your Turn

1. Why do we need the `set.seed` line before doing our `initial_split`? If you're not sure, try changing the number inside `set.seed`, or commenting out the line, and re-running the chunk a few times.

## Stratified Random Sampling

In stratified random sampling, we divide the dataset into very large groups, and then take a simple random sample from each group.

In a "training/test" split, stratified random sampling usually divides the dataset based on the *response* variable to be predicted. This is especially helpful when we have a highly imbalanced categorical response (almost all of the data is in one class) or outliers in a numerical response, because it ensures that the distribution of the response variable is similar in both sets.

In the example code below, we stratify by `GRADE`, ensuring that the proportion of A/B/C grades in the sample is roughly the same as in our population.

```{r}
#| label: stratified random sampling

set.seed(1338)
inspections_strat <- inspections |>
  initial_split(
    prop = 0.05,
    strata = GRADE
    ) |>
  training() # extract the selected rows of the dataset

```

## Cluster Sampling

In cluster sampling, we divide the dataset into many smaller groups, and then take a simple random sample *of* the groups.

In a "training/test" split, cluster sampling usually divides the dataset to ensure that "linked" observations stay together. For example, if your dataset consists of sessions on a website, you may want all sessions from the same user in the training (or test) set rather than split between them.

In the example code below, we group by `FACILITY_ID`, ensuring that if one inspection at a facility is in the sample, all of them are.

```{r}
#| label: cluster sampling

set.seed(1306)
inspections_cluster <- inspections |>
  group_initial_split(
    prop = 0.05,
    group = FACILITY_ID
    ) |>
  training() # extract the selected rows of the dataset

```

### Your Turn

1. How many inspections in the dataset were for Randy's Donuts on Manchester Blvd in Inglewood (`FACILITY_ID` == "FA0046001")? How many of those inspections ended up in each of the simple, stratified, and cluster random samples?

2. Pick one other variable in the `inspections` dataset. Determine whether it would make more sense to *stratify* or *cluster* based on that variable, then write code to do either stratified random sampling or cluster random sampling based on that variable.

## Time-Based Split

When doing a "training-test" split, we typically don't want to predict *past* responses based on *future* information, as this doesn't make sense for modeling. Therefore, we often split based on *time*.

```{r}
inspections_time <- inspections |>
  mutate(
    date = ymd_hms(ACTIVITY_DATE)
  ) |>
  arrange(date) |>
  initial_time_split(prop = 0.75) |> 
  training()
```

